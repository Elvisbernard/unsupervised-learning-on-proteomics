{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "669f2e08-8bf9-4d83-9b57-8b92abeb41e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa54a015-cfdd-4ff8-a379-4ff7d4248a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "leiden=pd.read_csv('/Users/Evelyn/Documents/UKB/materials/leidenA.csv')\n",
    "k3=pd.read_csv('/Users/Evelyn/Documents/UKB/materials/clust_3kA.csv')\n",
    "comp=pd.read_csv('/Users/Evelyn/Documents/UKB/materials/clusterv_compA.csv')\n",
    "clust2=pd.read_csv('/Users/Evelyn/Documents/UKB/materials/clusterv2A.csv').merge(leiden[['eid']])\n",
    "dftot = pd.read_csv('/Users/Evelyn/Documents/UKB/materials/3k_prot_v1.csv').iloc[:,:-2].merge(leiden[['eid']])\n",
    "df = pd.read_csv('/Users/Evelyn/Documents/UKB/materials/3kprot_all_expression_new.csv')\n",
    "outcomelong=pd.read_csv('/Users/Evelyn/Documents/UKB/materials/outcomelong.csv').merge(leiden[['eid']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "682176bf-bdf9-4539-9787-91cfe77bdd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate clusters based on protein abundance\n",
    "def recreate(scale, prot_list, inclust_people, disease_name, total_sick, total_people, percentage_num, level=None):\n",
    "    tempdf = dftot[['eid']+prot_list].dropna()\n",
    "    # Calculate the quantile\n",
    "    quantiles = {}     \n",
    "    for prot in prot_list:\n",
    "        quantiles[prot] = {}\n",
    "        if level is None:\n",
    "            loop_range = range(0, percentage_num)\n",
    "            for i in loop_range:\n",
    "                a = i / 100\n",
    "                quantiles[prot][a] = inclust_people[prot].quantile(a)\n",
    "        else:\n",
    "            loop_range = range(100, percentage_num, -1)   \n",
    "            for i in loop_range:\n",
    "                a = i / 100\n",
    "                quantiles[prot][a] = inclust_people[prot].quantile(a)\n",
    "        num_quantiles = len(loop_range)\n",
    "        \n",
    "    # Analysis of all proteins          \n",
    "    diction = {}\n",
    "    all_rows = []\n",
    "    for i in loop_range:\n",
    "        a = i / 100\n",
    "        tempdf_new = tempdf.copy()\n",
    "        for prot in prot_list:\n",
    "            l = quantiles[prot][a]\n",
    "            if level is None:\n",
    "                tempdf_new = tempdf_new[tempdf_new[prot] > l]\n",
    "            else:\n",
    "                tempdf_new = tempdf_new[tempdf_new[prot] < l]             \n",
    "        had_disease = tempdf_new[['eid']].merge(outcomelong, on='eid', how='left')\n",
    "        had_disease = (had_disease[disease_name] == 1).values\n",
    "        people = len(tempdf_new['eid'])\n",
    "        sick_count = int(had_disease.sum())\n",
    "        if people == 0:\n",
    "            ratio1 = 0\n",
    "            ratio2 = 0\n",
    "        else:\n",
    "            ratio1 = (sick_count / people) * 100\n",
    "            ratio2 = (sick_count / people) / (total_sick / total_people)\n",
    "        all_rows.append((a, people, sick_count, ratio1, ratio2))\n",
    "    \n",
    "    for idx in range(len(all_rows)):\n",
    "        a, people, sick_count, ratio1, ratio2 = all_rows[idx]\n",
    "        if people > 0:\n",
    "            try:\n",
    "                contingency_table = [[sick_count, people - sick_count],[total_sick, total_people - total_sick]]\n",
    "                _, raw_p, _, _ = chi2_contingency(contingency_table)\n",
    "                corrected_p = min(raw_p * num_quantiles, 1.0)\n",
    "                p_value = corrected_p\n",
    "            except:\n",
    "                p_value = np.nan\n",
    "        else:\n",
    "            p_value = np.nan\n",
    "        diction[a] = (people, sick_count, '{:.2f}%'.format(ratio1), ratio2, p_value)    \n",
    "    mydf = pd.DataFrame.from_dict(diction, orient='index', columns=['all_prot', 'sick_count', 'sick_percentages', 'OR', 'p_value'])\n",
    "    mydf.rename(columns={'index': 'key'}, inplace=True)\n",
    "\n",
    "    # Analysis after removing a protein\n",
    "    all_data = []\n",
    "    prot_names = [] \n",
    "    for col in range(1, len(prot_list) + 1):\n",
    "        prot = tempdf.columns[col]\n",
    "        prot_names.append(prot)\n",
    "        temp = tempdf.drop(tempdf.columns[col], axis=1)\n",
    "        prot_rows = []\n",
    "        for i in loop_range:\n",
    "            a = i / 100\n",
    "            tempdf_new = temp.copy()\n",
    "            for prot in temp.columns.tolist()[1:]:\n",
    "                l = quantiles[prot][a]\n",
    "                if level is None:\n",
    "                    tempdf_new = tempdf_new[tempdf_new[prot] > l]\n",
    "                else:\n",
    "                    tempdf_new = tempdf_new[tempdf_new[prot] < l]     \n",
    "            had_disease = tempdf_new[['eid']].merge(outcomelong, on='eid', how='left')\n",
    "            had_disease = (had_disease[disease_name] == 1).values\n",
    "            people = len(tempdf_new['eid'])\n",
    "            sick_count = int(had_disease.sum())\n",
    "            if people == 0:\n",
    "                ratio1 = 0\n",
    "                ratio2 = 0\n",
    "            else:\n",
    "                ratio1 = (sick_count / people) * 100\n",
    "                ratio2 = (sick_count / people) / (total_sick / total_people)\n",
    "            prot_rows.append((a, people, sick_count, ratio1, ratio2))\n",
    "        prot_dict = {}\n",
    "        for idx in range(len(prot_rows)):\n",
    "            a, people, sick_count, ratio1, ratio2 = prot_rows[idx]\n",
    "            \n",
    "            if people > 0:\n",
    "                try:\n",
    "                    contingency_table = [[sick_count, people - sick_count],[total_sick, total_people - total_sick]]\n",
    "                    _, raw_p, _, _ = chi2_contingency(contingency_table)\n",
    "                    corrected_p = min(raw_p * num_quantiles, 1.0)\n",
    "                    p_value = corrected_p\n",
    "                except:\n",
    "                    p_value = np.nan\n",
    "            else:\n",
    "                p_value = np.nan\n",
    "            prot_dict[a] = (people, sick_count, '{:.2f}%'.format(ratio1), ratio2, p_value)\n",
    "        data = pd.DataFrame.from_dict(prot_dict, orient='index')\n",
    "        all_data.append(data)\n",
    "\n",
    "    # Create table\n",
    "    concat_df = pd.concat(all_data, axis=1)\n",
    "    mydf2 = pd.DataFrame(concat_df)\n",
    "    new_names = []\n",
    "    for name in prot_names:\n",
    "        new_names.extend([f'{name}_{i}' for i in ['deleted','sick_count','sick_percentages','OR','p_value']])\n",
    "    mydf2.columns = new_names    \n",
    "    result_df = pd.concat([mydf, mydf2], axis=1)\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5371edf0-7869-45e3-a1e5-4b3ca45c3bdd",
   "metadata": {},
   "source": [
    "## fig 3b celiac 53 prot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db2ed2ab-9978-4ade-962f-78b91b33c92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common proteins in celiac clusters\n",
    "c1 = df[(df['file']=='comp')&(df['cluster']=='cl2')]\n",
    "c2 = df[(df['file']=='comp')&(df['cluster']=='cl3')]\n",
    "c3 = df[(df['file']=='3k')&(df['cluster']=='cl6')]\n",
    "c4= df[(df['file']=='leiden')&(df['cluster']=='cl7')]\n",
    "celi_prot = list(set(c1['protein']).intersection(c2['protein']).intersection(c3['protein']).intersection(c4['protein']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "037f689e-dea1-41a3-861b-a02b16ceb3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Participants in celiac clusters\n",
    "h1 = comp[comp['cl2']==1]\n",
    "h2 = comp[comp['cl3']==1]\n",
    "h3 = k3[k3['cl6']==1]\n",
    "h4 = leiden[leiden['cl7']==1] \n",
    "incl_celi = h1[['eid']].merge(h2[['eid']], how='outer').merge(h3[['eid']], how='outer').merge(h4[['eid']], how='outer')\n",
    "incl_celi_dftot = incl_celi.merge(dftot,on='eid',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cceb4f2f-4b13-4f1a-95ee-dc08ffee23a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = recreate('a_to_1', celi_prot, incl_celi_dftot, 'K90 Intestinal malabsorption', 357, 45174, 76)\n",
    "result_df.to_csv('fig 3b celiac 53 prot.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc7248e-0680-4711-944a-9b27720c43b2",
   "metadata": {},
   "source": [
    "## fig 3e leukemia 134 prot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0683a46d-359b-473f-8da6-ee19cf62a56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common proteins in leukemia clusters\n",
    "l1 = df[(df['file']=='comp')&(df['cluster']=='cl5')]\n",
    "l2 = df[(df['file']=='comp')&(df['cluster']=='cl7')]\n",
    "l3 = df[(df['file']=='cluster2')&(df['cluster']=='cl1')]\n",
    "l4 = df[(df['file']=='cluster2')&(df['cluster']=='cl5')]\n",
    "l5 = df[(df['file']=='3k')&(df['cluster']=='cl16')]\n",
    "l6 = df[(df['file']=='leiden')&(df['cluster']=='cl10')]\n",
    "leuk_prot = list(set(l1['protein']).intersection(l2['protein']).intersection(l3['protein']).intersection(l4['protein']).intersection(l5['protein']).intersection(l6['protein']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34b1853b-5e3d-47b6-ae8e-c74c4abc5a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Participants in leukemia clusters\n",
    "h1 = comp[comp['cl5']==1]\n",
    "h2 = comp[comp['cl7']==1]\n",
    "h3 = clust2[clust2['cl1']==1]\n",
    "h4 = clust2[clust2['cl5']==1]\n",
    "h5 = k3[k3['cl16']==1]\n",
    "h6 = leiden[leiden['cl10']==1] \n",
    "incl_leuk = h1[['eid']].merge(h2[['eid']], how='outer').merge(h3[['eid']], how='outer').merge(h4[['eid']], how='outer').merge(h5[['eid']], how='outer').merge(h6[['eid']], how='outer')\n",
    "incl_leuk_dftot = incl_leuk.merge(dftot,on='eid',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4e6da51-f368-4e5e-a53c-071046e5b4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df= recreate('a_to_1', leuk_prot, incl_leuk_dftot, 'C91 Lymphoid leukaemia', 119,45174, 76)\n",
    "result_df.to_csv('fig 3e leukemia 134 prot.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e384b1-5a24-4bbc-a3f8-4d01771ed6d2",
   "metadata": {},
   "source": [
    "## fig 3c/3d hypertension 77 prot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cdca5fc1-0b1f-4037-aaff-7863faf14d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common proteins in hypertension clusters\n",
    "hy1 = df[(df['file']=='leiden')&(df['cluster']=='cl1')] \n",
    "hy2 = df[(df['file']=='leiden')&(df['cluster']=='cl2')] \n",
    "hy3 = df[(df['file']=='leiden')&(df['cluster']=='cl5')] \n",
    "hy4 = df[(df['file']=='leiden')&(df['cluster']=='cl6')]\n",
    "hy5 = df[(df['file']=='leiden')&(df['cluster']=='cl15')] \n",
    "hy6 = df[(df['file']=='cluster2')&(df['cluster']=='cl7')] \n",
    "hyp_prot = list(set(hy1['protein']).intersection(hy2['protein']).intersection(hy3['protein']).intersection(hy4['protein']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf8aab87-9c56-4710-986b-36c797338043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Participants in hypertyension clusters\n",
    "inh1 = leiden[leiden['cl1']==1] \n",
    "inh2 = leiden[leiden['cl2']==1] \n",
    "inh3 = leiden[leiden['cl5']==1] \n",
    "inh4 = leiden[leiden['cl6']==1] \n",
    "inh5 = leiden[leiden['cl15']==1]  \n",
    "inh6 = clust2[clust2['cl7']==1]  \n",
    "incl_hyp = inh1[['eid']].merge(inh2[['eid']], how='outer').merge(inh3[['eid']], how='outer').merge(inh4[['eid']], how='outer')\n",
    "incl_hyp_dftot = incl_hyp.merge(dftot,on='eid',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d5bf105-3742-4daa-8ccb-69023e5306f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_h = recreate('a_to_1', hyp_prot, incl_hyp_dftot,'I10 Essential (primary) hypertension' ,14996, 45174 , 76)\n",
    "result_l = recreate('a_to_0', hyp_prot, incl_hyp_dftot, 'I10 Essential (primary) hypertension', 14996, 45174, 24, level='low')\n",
    "result_h.to_csv('fig 3c hypertension 77 prot.csv')\n",
    "result_l.to_csv('fig 3d hypertension 77 prot.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211d3adc-fa5b-42d6-8268-1ad1ae5ea320",
   "metadata": {},
   "source": [
    "## s2 a/b hypertension 10 prot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6f72ba3-3da7-4bfe-9e77-7fece360b440",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp_prot_withB15 = list(set(hy1['protein']).intersection(hy2['protein']).intersection(hy3['protein']).intersection(hy4['protein']).intersection(hy5['protein']))\n",
    "incl_hyp_withB15 = inh1[['eid']].merge(inh2[['eid']], how='outer').merge(inh3[['eid']], how='outer').merge(inh4[['eid']], how='outer').merge(inh5[['eid']], how='outer')\n",
    "incl_hyp_dftot_withB15 = incl_hyp_withB15.merge(dftot,on='eid',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06b6982f-226b-4c12-9ba9-5f847768c290",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_h = recreate('a_to_1', hyp_prot_withB15, incl_hyp_dftot_withB15,'I10 Essential (primary) hypertension',14996, 45174 , 76)\n",
    "result_l = recreate('a_to_0', hyp_prot_withB15, incl_hyp_dftot_withB15, 'I10 Essential (primary) hypertension', 14996, 45174, 24, level='low')\n",
    "result_h.to_csv('s2 a hypertension 10 prot.csv')\n",
    "result_l.to_csv('s2 b hypertension 10 prot.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478b4fce-5a2d-48b2-8de1-66582944c624",
   "metadata": {},
   "source": [
    "## s2 c/d hypertension 12 prot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05f0a538-af21-42d9-a5c3-9a8b25e0051f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp_prot_withA7 = list(set(hy1['protein']).intersection(hy2['protein']).intersection(hy3['protein']).intersection(hy4['protein']).intersection(hy6['protein']))\n",
    "incl_hyp_withA7 = inh1[['eid']].merge(inh2[['eid']], how='outer').merge(inh3[['eid']], how='outer').merge(inh4[['eid']], how='outer').merge(inh6[['eid']], how='outer')\n",
    "incl_hyp_dftot_withA7 = incl_hyp_withA7.merge(dftot,on='eid',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a355fa1-f863-412e-a4ab-0b9068fc9b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_h = recreate('a_to_1', hyp_prot_withA7, incl_hyp_dftot_withA7,'I10 Essential (primary) hypertension' ,14996, 45174 , 76)\n",
    "result_l = recreate('a_to_0', hyp_prot_withA7, incl_hyp_dftot_withA7, 'I10 Essential (primary) hypertension', 14996, 45174, 24, level='low')\n",
    "result_h.to_csv('s2 c hypertension 12 prot.csv')\n",
    "result_l.to_csv('s2 d hypertension 12 prot.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d75becd-8216-449e-b4b9-b8ee5a12487c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (data_analysis)",
   "language": "python",
   "name": "data_analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
